{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a487a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob                         # this module helps in selecting files \n",
    "import pandas as pd                 # this module helps in processing CSV files\n",
    "import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66affaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-21 12:41:40--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4249 (4.1K) [application/zip]\n",
      "Saving to: ‘datasource.zip’\n",
      "\n",
      "datasource.zip      100%[===================>]   4.15K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-03-21 12:41:41 (1013 MB/s) - ‘datasource.zip’ saved [4249/4249]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232f6be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  datasource.zip\r\n",
      "  inflating: used_car_prices1.csv    \r\n",
      "  inflating: used_car_prices2.csv    \r\n",
      "  inflating: used_car_prices3.csv    \r\n",
      "  inflating: used_car_prices1.json   \r\n",
      "  inflating: used_car_prices2.json   \r\n",
      "  inflating: used_car_prices3.json   \r\n",
      "  inflating: used_car_prices1.xml    \r\n",
      "  inflating: used_car_prices2.xml    \r\n",
      "  inflating: used_car_prices3.xml    \r\n"
     ]
    }
   ],
   "source": [
    "!unzip datasource.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf64a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile    = \"temp.tmp\"               # file used to store all extracted data\n",
    "logfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\n",
    "targetfile = \"transformed_data.csv\"   # file where transformed data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1f86361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV extract function below\n",
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f012570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON extract function below\n",
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process, lines= True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3814aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n",
    "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n",
    "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n",
    "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1a97985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the price columns to 2 decimal places\n",
    "def transform(data):\n",
    "    data['price'] = round(data.price,2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bc38712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(target_file, data_to_load):\n",
    "    data_to_load.to_csv(target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7714dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(msg):\n",
    "    timestamp_format = \"%H:%M:%S-%h-%d-%Y\"\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"dealership_logfile.txt\", \"a\") as f:\n",
    "        f.write(timestamp + \",\" + msg + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7489d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log that you have started the ETL process\n",
    "log(\"ETL job start\")\n",
    "\n",
    "# Log that you have started the Extract step\n",
    "log(\"Extract start\")\n",
    "\n",
    "# Call the Extract function\n",
    "extracted_data = extract()\n",
    "\n",
    "# Log that you have completed the Extract step\n",
    "log(\"Extract End\")\n",
    "\n",
    "# Log that you have started the Transform step\n",
    "log(\"Transform start\")\n",
    "\n",
    "# Call the Transform function\n",
    "transformed_data = transform(extracted_data)\n",
    "# Log that you have completed the Transform step\n",
    "log(\"Transform_complete\")\n",
    "\n",
    "# Log that you have started the Load step\n",
    "log(\"Load start\")\n",
    "\n",
    "# Call the Load function\n",
    "load(targetfile, transformed_data)\n",
    "\n",
    "# Log that you have completed the Load step\n",
    "log(\"Load end\")\n",
    "\n",
    "# Log that you have completed the ETL process\n",
    "log(\"ETL Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8225a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c0568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb3c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea8eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
